{
 "metadata": {
  "name": "Pratica1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u00cdndices invertidos e busca booleana\n",
      "===================================\n",
      "\n",
      "_Fl\u00e1vio Code\u00e7o Coelho (Com a contribui\u00e7\u00e3o dos alunos do curso de Sistemas de recupera\u00e7\u00e3o de Informa\u00e7\u00f5es da EMAp)_\n",
      "\n",
      "Nesta pr\u00e1tica, vamos contruir um indice invertido e uma m\u00e1quina de busca booleana simples.\n",
      "\n",
      "Para agilizar nosso trabalho, vamos utilizar a biblioteca [NLTK](http://nltk.org) para processamento de linguagem natural."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Em seguida vamos importar mais coisas necess\u00e1rias para o nosso trabalho. Note que estamos baixando a obra completa de Machado de Assis, com a qual iremos alimentar nosso \u00edndice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import machado\n",
      "from nltk.tokenize import WordPunctTokenizer\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "from collections import defaultdict\n",
      "from nltk.stem.snowball import PortugueseStemmer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos tamb\u00e9m baixar o banco de *stopwords* do NLTK. Stop words s\u00e3o um conjunto de palavras que normalmente carregam baixo conte\u00fado sem\u00e2ntico e portanto n\u00e3o s\u00e3o alvo de buscas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.download('stopwords')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package 'stopwords' to\n",
        "[nltk_data]     /home/fccoelho/nltk_data...\n",
        "[nltk_data]   Package stopwords is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lendo o texto *puro* dos livros de Machado:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textos = [machado.raw(id) for id in machado.fileids()]\n",
      "len(textos)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "246"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Carregando a  lista de stopwords em lingua portuguesa para limpeza dos textos. Note que \u00e9 preciso trazer as palavras para *UTF-8* antes de us\u00e1-las."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sw = stopwords.words('portuguese') + list (string.punctuation)\n",
      "swu = [word.decode('utf8') for word in sw]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Um outro ingrediente essencial \u00e9 um stemmer para a nossa l\u00edngua. O Stemmer reduz as palavras a uma abrevia\u00e7\u00e3o que se aproxima da \"raiz\" da palavra."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmer = PortugueseStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Preparando o Texto\n",
      "------------------\n",
      "\n",
      "Na c\u00e9lula abaixo, vamos normalizar os nossos textos trazendo todas as palavras para caixa baixa e abreviando-as de forma a deixar apenas as suas ra\u00edzes. Neste passo, removeremos tamb\u00e9m as *stopwords*. Tenha paci\u00eancia, esta an\u00e1lise vai levar algum tempo..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textos_limpos = []\n",
      "for texto in textos:\n",
      "    tlimpo = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
      "    textos_limpos.append(tlimpo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vejamos uma amostra do resultado:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "textos_limpos[0][150:160]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[u'uma',\n",
        " u'tal',\n",
        " u'miss',\n",
        " u'doll',\n",
        " u'dev',\n",
        " u'ter',\n",
        " u'poet',\n",
        " u'tennyson',\n",
        " u'cor',\n",
        " u'ler']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Construindo um \u00cdndice Invertido\n",
      "-------------------------------\n",
      "\n",
      "De posse da nossa lista de termos *normalizados*, podemos agora construir o nosso \u00edndice invertido."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indice = defaultdict(lambda:set([]))\n",
      "for tid,t in enumerate(textos_limpos):\n",
      "    for term in t:\n",
      "        indice[term].add(tid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Podemos verificar a estrutura interna do nosso \u00edndice, procurando por uma palavra:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indice[stemmer.stem(u\"Sal\u00e1rio\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "set([192, 193, 3, 165, 232, 77, 51, 182, 219, 220, 222])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamo ver o contexto em que a palavra *Sal\u00e1rio* ocorre em um dos textos"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.Text(textos[193].encode('utf8').split()).concordance(\"Sal\u00e1rio\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Building index...\n",
        "Displaying 2 of 2 matches:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "etite. Os paredistas queriam maior sal\u00e1rio e buscavam o pior caminho. H\u00e1 mei\n",
        " trabalhadeiras levam os saldos do sal\u00e1rio e os lucros advent\u00edcios, eis a\u00ed \n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def busca(consulta):\n",
      "    \"\"\"\n",
      "    A constru\u00e7\u00e3o de uma fun\u00e7\u00e3o de busca \u00e9 deixada com exerc\u00edcio ao leitor\n",
      "    \"\"\"\n",
      "    pass\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mas j\u00e1 podemos utilizar nosso \u00edndice diretamente com alguns termos e verificar como o mesmo \u00e9 eficiente. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time\n",
      "results = indice[stemmer.stem('nacional')]&indice[stemmer.stem('perdi')] - indice[stemmer.stem('campo')]\n",
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0.00 s, sys: 0.00 s, total: 0.00 s\n",
        "Wall time: 0.00 s\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "set([155,\n",
        "     164,\n",
        "     69,\n",
        "     137,\n",
        "     138,\n",
        "     171,\n",
        "     235,\n",
        "     141,\n",
        "     219,\n",
        "     144,\n",
        "     49,\n",
        "     189,\n",
        "     84,\n",
        "     122,\n",
        "     87,\n",
        "     73,\n",
        "     154,\n",
        "     27,\n",
        "     61,\n",
        "     95])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para um exame mais preciso do tempo de execu\u00e7\u00e3o da nossa consulta, podemos usar a m\u00e1gica do *%%timeit*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "results = indice[stemmer.stem('nacional')]&indice[stemmer.stem('perdi')] - indice[stemmer.stem('campo')]\n",
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 69.7 us per loop\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}